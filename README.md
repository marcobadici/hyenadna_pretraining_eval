# Seminar Praktikum - Evaluation of the effect of pre-training on HyenaDNA models of varying sizes on genomic sequence classification tasks  

This project investigates the impact of pre-training on the performance of HyenaDNA models in genomic sequence classification tasks, comparing
fine-tuning pre-trained models with training from scratch. Utilizing datasets from GenomicBenchmarks, the study evaluates both small (1k tokens) 
and large (1 million tokens) model configurations to determine if pre-training benefits scale with model size. The results provide insights into
optimizing computational resources and training protocols, suggesting that pre-training may not always be necessary and could be enhanced by using 
different genomic datasets or longer sequence tasks. The project includes detailed methodologies, performance metrics, and analysis outcomes to 
guide future genomic model development.


## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

What things you need to install the software and how to install them

```
Give examples
```

### Installing

A step by step series of examples that tell you how to get a development env running

Say what the step will be

```
Give the example
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo

## Running the tests

Explain how to run the automated tests for this system

### Break down into end to end tests

Explain what these tests test and why

```
Give an example
```

### And coding style tests

Explain what these tests test and why

```
Give an example
```

## Deployment

Add additional notes about how to deploy this on a live system





## Authors

* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)

See also the list of [contributors](https://github.com/your/project/contributors) who participated in this project.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Hat tip to anyone whose code was used
* Inspiration
* etc
